<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Samiran Gode</title>

  <meta name="author" content="Samiran Gode">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Samiran Gode</name>
              </p>
              <!-- <p>Hi! I am a graduate student at <a href="https://www.cmu.edu/">Carnegie Mellon University</a> in the Mechanical Engineering Department, majoring in Robotics. I am fortunate to be a part of the <a href="https://rpl.ri.cmu.edu/">Robot Perception Lab</a>, where I get to work on Object SLAM.
                Before this I was an intern at the Data Science team at <a href="https://jupiter.money/">Jupiter</a>, a neobank for millenials, from July 2020 to December 2020. I worked on FAQ search using NLP and was responsible for setting up user behaviour analytics using Segment and Amplitude.
              </p> -->
              <!-- <p>Hello! I am a recent graduate of <a href="https://www.cmu.edu/">Carnegie Mellon University</a> where I was fortunate to be a part of the <a href="https://rpl.ri.cmu.edu/">Robot Perception Lab</a>.
                 At CMU, I worked on Underwater Perception and Object SLAM, I now work for a startup as a Robotics Software Engineer.
              </p> -->
              <p>
                Hello! I am an <a href="https://ellis.eu/">ELLIS PhD</a> Student advised by Professor <a href="https://www.utn.de/person/wolfram-burgard-2/">Wolfram Burgard</a> and co-advised by Professor <a href="https://cordeliaschmid.github.io/">Cordelia Schmid</a>. My research interests span a lot of fields but broadly
                I work on building robust models for robot perception across multiple modalities - vision, language, sonar, audio etc. and their use in downstream applications such as robot navigation.
              </p>
              <p>
                I am a graduate of <a href="https://www.cmu.edu/">Carnegie Mellon University</a> where I was fortunate to be a part of the <a href="https://rpl.ri.cmu.edu/">Robot Perception Lab</a>.
                At CMU, I worked on Underwater Perception and Object SLAM. I was also a Robotics Software Engineer at a startup where I worked on the localization stack
                for a mobile robot system.
              </p>
              <p>
                <!-- At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>. -->
                <!-- I was a Project Assistant at IISc working on project <a href="https://imprint-india.org/intelligent-water-supply-network-monitoring-and-control-for-equitable-distribution-of-water-within-a-mega-city-eqwater">EqWATER</a> from July 2019 to July 2020. My work involved detecting leaks in a cyber-physical water distribution system which would be applied to the Bangalore water supply. Before that, I was an Area Manager Intern at Amazon for about 6 months from Jan 2019 to Jun 2019. I have spent the summer after my junior year at TIFR, working on Image Processing and the summer after my sophomore year at Putzmeister, working on Robotics.

                I completed my undergrad from BITS Pilani, Pilani in 2019 -->
                Before that I interned with <a href="https://jupiter.money/">Jupiter's</a> Data Science team, focusing on NLP for FAQ search and user behavior analytics.
                Additionally, I contributed to the EqWATER project at IISc, specializing in leak detection for smart water distribution systems. I've also gained valuable experience as an Area Manager Intern at Amazon.
              </p>
              <p style="text-align:center">
                <a href="mailto:samiran.gode.applications@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="https://drive.google.com/file/d/17JPkwsdaH9hF6hElO2zKbIRabJcg2bnN/view?usp=drive_link">CV(Computer Vision)</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1VNcyal6uNA1D5e_I3rZ33DhJ9U6C043Z/view?usp=drive_link">CV(SLAM)</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://drive.google.com/file/d/1GO9PN9KHWhV7jtHCJZbZxl6gNd0OB7Xx/view?usp=drive_link">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=zIil-dQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/samirangode">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/samiran-gode-901941178/">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="./assets/images/2015ABPS0821P.jpg"><img style="width:100%;max-width:100%;border-radius: 5%;" alt="profile photo" src="./assets/images/2015ABPS0821P.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- Table for news -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr> <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                  <li> [Mar'25] AADG accepted to the SynthData Workshop at ICLR 2025!<br>
                  <li> [Nov'24] Presenting our work FlowNav in workshops at CoRL 2024</a>.<br>
                  <li> [Jun'24] Started my PhD as an ELLIS PhD student</a>.<br>
                  <!-- <li> [Dec'23] Our work on detecting leaks in water distribution systems has been accepted at AAAI'24 AI4TS workshop </a>.<br> -->
                  <li> [Jan'24] SONIC accepted at ICRA 2024</a>.<br>
                  <li> [Oct'23] Participated in Closing the Loop on Localization workshop at IROS 2023</a>.<br>
                  <li> [Oct'23] Presented our work SONIC at the Advanced Marine Robotics Workshop at IROS 2023</a>.<br>
                  <li> [Sep'23] Submitted one paper to ICRA'24<br>
                  <li> [Aug'23] Our <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/aaai.12104">paper</a> was published at the AI Magazine!<br>
                  <li> [Feb'23] Presented our work on Understanding Political Polarization using Language Models at AAAI'23 AI4CEW<br>
                  <li> [Dec'22] Graduated from CMU!<br>
              </ul>
            </td> </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                * denotes equal contribution
                <!-- I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='assets/images/flownav_architecture_resized.png' width="190">
                <!-- <img src='./assets/images/FlowNav-architecture_small.png' class="img-fluid" alt="Network Architecture"> -->
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>FlowNav: Combining Flow Matching and Depth Priors for Efficient Navigation</papertitle>
              <br>
              <strong>Samiran Gode*</strong>,
              <a href="https://abhijeetknayak.github.io/">Abhijeet Nayak*</a>,
              <a href="https://scholar.google.com/citations?user=wbhS4_sAAAAJ&hl=en">D√©bora N.P. Oliveira*</a>,
              <a href="https://cordeliaschmid.github.io/">Cordelia Schmid</a>,
              <a href="https://www.utn.de/person/wolfram-burgard-2/">Wolfram Burgard</a>,
              <br>
              <em><strong>IROS</strong></em>, 2025[Submitted] <br>
              <em>CoRL Workshop on Learning Effective Abstractions for Planning (LEAP)</em>, 2024 <br>
              <em>CoRL Workshop on Differentiable Optimization Everywhere: Simulation, Estimation, Learning, and Control</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2411.09524">arXiv</a>
              /
              <a href="https://utn-air.github.io/flownav.github.io/">Website</a>
              <p></p>
              <p>
                - Used Conditional Flow Matching(CFM) along with depth embeddings for efficient goal-conditioned robot navigation as opposed to diffusion policies <br>
                - Achieved the higher accuracy and runtime efficiency compared to the SOTA.<br>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='./assets/images/SONIC.png' width="160" height="120">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SONIC: Sonar Image Correspondence using Pose Supervised Learning for Imaging Sonars</papertitle>
              <br>
              <strong>Samiran Gode*</strong>,
              <a href="https://akshayhinduja.github.io/">Akshay Hinduja*</a>,
              <a href="https://www.cs.cmu.edu/~kaess/">Michael Kaess</a>,
              <br>
              <em><strong>ICRA</strong>,</em> 2024<br>
              <em>2nd Advanced Marine Robotics TC Workshop IROS</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2310.15023">arXiv</a>
              /
              <a href="https://github.com/rpl-cmu/sonic">Code</a>
              <!-- /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                - Solved data association for underwater SLAM through a novel method for sonar image correspondence using Learned Features. <br>
                - Introduced a pose-supervised network that generates feature descriptors robust to changes in
                  viewpoints, enabling more reliable feature matches in sonar based localization and mapping. <br>
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='assets/images/AADG3.png' width="190" height="120">
                <!-- <img src='./assets/images/FlowNav-architecture_small.png' class="img-fluid" alt="Network Architecture"> -->
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Did You Hear That? Introducing AADG: A Framework for Generating Benchmark Data in Audio Anomaly Detection</papertitle>
              <br>
              <a href="https://www.linkedin.com/in/ksheerajaraghavan">Ksheeraja Raghavan*</a>,
              <strong>Samiran Gode*</strong>,
              <a href="https://ankitshah009.github.io/">Ankit P Shah*</a>,
              <a href="https://in.linkedin.com/in/surabhi-raghavan">Surabhi Raghavan</a>,
              <a href="https://www.utn.de/person/wolfram-burgard-2/">Wolfram Burgard</a>,
              <a href="https://cmu-mlsp.github.io/team/bhiksha_raj">Bhiksha Raj</a>,
              <a href="http://ayesha.lti.cs.cmu.edu/mlsp/people/rsingh/index.html">Rita Singh</a>,
              <br>
              <em>ICLR Workshop on "Will Synthetic Data Finally Solve the Data Access Problem?"</em>, 2025 <br>
              <a href="https://openreview.net/pdf?id=pqjGPFMWnN">Openreview</a>
              <p></p>
              <p>
                - Developed a novel audio generation framework (AADG) using LLMs and text-to-audio models to simulate realistic scenarios specifically for Audio Anomaly Detection and Localization.<br>
                - Expanded anomaly detection datasets beyond industrial sounds, addressing diverse real-world environments like telephonic or video-derived audio.<br>
                - Created a modular, rigorously verified framework enabling scalable and reliable generation of realistic audio data, 
                  improving robustness of anomaly detection models against out-of-distribution scenarios.<br>
              </p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='assets/images/combined_image.jpg' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://arxiv.org/abs/2301.00891"> -->
              <a href="https://doi.org/10.1002/aaai.12104"></a>
                <papertitle>Understanding Political Polarization using Language Models: A dataset and method</papertitle>
              </a>
              <br>
              <strong>Samiran Gode</strong>,
              Supreeth Bare,
              <a href="http://mlsp.cs.cmu.edu/people/bhiksha/">Bhiksha Raj</a>,
							Hyungon(Clay) Yoo
              <br>
              <em> <strong>AI Magazine</strong> <br>The AAAI 2023 Second Workshop on AI for Credible Elections</em>
              <br>
              <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/aaai.12104">Journal</a>
              /
              <a href="https://arxiv.org/abs/2301.00891">arXiv</a>
              /
              <a href="https://github.com/samirangode/Understanding_Polarization">Code</a>
              <p></p>
              <p>
                - Finetuned Longformer on a scraped Wikipedia dataset to find most important tokens based on attention score.<br>
                - Used other conventional techniques such as Word2Vec, Doc2Vec and BERT based models understand words which lead to polarisation.<br>
                - Paper accepcted at AAAI 2023 Workshop on AI for credible elections and selected for publication at the AI Magazine Fall 2023.<br>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <!-- <img src='./assets/images/tetrahedron_gif.gif' width="160" height="160"> -->
                <img src='./assets/images/quadric.gif' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

                <papertitle>Quadric SLAM</papertitle>

              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                <!-- Representing a map around a quadric. -->
                - Implemented on Object based semantic SLAM, created low-memory metric semantic maps for multi-robot communication.<br>
                - Formulated a graph based SLAM. Used quadric factors with the factor graph with underlying visual inertial odometry.<br>
                - Designed feature descriptors for SONAR using unsupervised learning for underwater SLAM.<br>
                - Used an encoder decoder structure with CNNs with custom loss functions to learn without labels.<br>
              </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='assets/images/combined_images_final.gif' width="160" height="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Detecting and Localizing Leaks in Intermittent Water Distribution Networks</papertitle>
              <br>
              <strong>Samiran Gode</strong>,
              Sheetal Kumar K R,
              Sindhu H J,
              P G Prasad,
              M S Mohan Kumar,
              <a href="https://ece.iisc.ac.in/~rajeshs/">Rajesh Sundaresan</a>,
              <br>
              <!-- <em>Artificial Intelligence for Time Series Analysis (AI4TS) Workshop AAAI</em>, 2024 -->
              <br>
              <p>
               - Developed an algorithm for detecting and localizing multiple leaks in Water Distribution Systems with Intermittent water
                supply for Bengaluru a city of 8.5mil.(As part of EqWATER funded by Ministry of Human Resources Development, Govern-
                ment of India).<br>
              - Automated intermittent water supply in an experimental system(60m long*100mm dia network, 4L/s) using LabVIEW to
              generate scaled-down comparable data with identical disturbances and leaks analogous to field data.
              </p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
              <p>
                <!-- I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='./assets/images/ICP.png' width="160" height="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>3D Dense SLAM system using ICP</papertitle>
              <p></p>
              <p>
                - Camera Localisation on the ICL-NUIM dataset using Iterative Closest Point Algorithm. <br>
                - Used point-based fusion to create a point cloud map
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='./assets/images/part_3.gif' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>NERF (Volume Rendering and Neural Radiance Fields)</papertitle>
              <br>
              <a href="https://github.com/samirangode/Volume-Rendering-and-Neural-Radiance-Fields">Code</a>
              <p>
                - Implemented a Differentiable Renderer for emission-absorption volumes.<br>
                - Implemented a ray sampler for optimising volume parameters.<br>
                - Used a MLP to map 3D positions to Volume Density and colour
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='./assets/images/particle_filter.gif' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

                <papertitle>Particle Filter</papertitle>

              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                <!-- Localisation using a particle filter. -->
                - Monte Carlo Localization(MCL) based robot localization for an indoor robot using laser rangefinder and odometry.<br>
                - Implemented the raycasting based sensor and motion model along with resampling.<br>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='./assets/images/plant.gif' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

                <papertitle>Single View to 3D</papertitle>

              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                Learning 3D representations using single views.
              </p>
            </td>
          </tr>




        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>


          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>


        </tbody></table> -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Thank you to <a href="https://jonbarron.info/">Jon Barron</a> for the website template!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
